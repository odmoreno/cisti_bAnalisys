Is Training Useful to Detect Deepfakes? : A Preliminary Study.
ABSTRACT
Generative Adversarial Networks (GANs) constitute a significant breakthrough due to their ability to generate realistic synthetic data. Sometimes, the synthetic creation resembles a real person or their voice, and we call them deepfakes. Deepfakes are used for multiple purposes, including malicious ones. This makes them a major concern due to the widespread lack of information about their existence and because they are increasingly generated more realistically. It is becoming increasingly difficult to differentiate them from real content. In this study, we evaluate human ability to differentiate between a real and a synthetic face. The results indicate that people are unable to differentiate between real images and deepfakes, but that some training slightly improves these results. Therefore, our hypothesis is that human accuracy in identifying synthetic faces could be improved with thorough training on how to detect deepfake faces.
