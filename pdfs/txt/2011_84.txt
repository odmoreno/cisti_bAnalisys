Spontaneous children's emotion recognition by categorical classification of acoustic features
ABSTRACT
This paper describes three categorical classification approaches to spontaneous children's emotion recognition based on acoustic features from speech. Also, we present a fourth approach combining by stacking generalisation the two best classifiers. We used the FAU Aibo Corpus to work under real-life conditions, dealing with spontaneous speech and with low emotional expressiveness, unbalanced data, non-prototypical emotions and a garbage class. Experiments were carried out using the leave-one-speaker-out strategy to consider speaker independence. Two different training and test sets were used at the end to validate the results. We selected the two best classifiers to be merged by comparing the results obtained in the leave-one-speaker-out stage. Experiments showed that the fusion of these classifiers resulted in a more robust structure when it had to classify previously unseen data.
